{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Owlready2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0s09-1yseh6",
        "outputId": "82bc258d-9838-47f9-a962-6539e29e71c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Owlready2\n",
            "  Downloading Owlready2-0.41.tar.gz (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Owlready2\n",
            "  Building wheel for Owlready2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Owlready2: filename=Owlready2-0.41-cp39-cp39-linux_x86_64.whl size=24160920 sha256=5dfae5796681bfae3cfd1d0c6156d77933a427d95c6f4cfba737084a59b59111\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/56/67/10bd2f89fc6262317ee02f4d8dbdff95f1db434b6bb18daed0\n",
            "Successfully built Owlready2\n",
            "Installing collected packages: Owlready2\n",
            "Successfully installed Owlready2-0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ngram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKQdpo4kPPbX",
        "outputId": "898f03b2-4797-4a1c-e352-f54e921eac49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ngram\n",
            "  Downloading ngram-4.0.3-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: ngram\n",
            "Successfully installed ngram-4.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-stringmatching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wei5eZTSITk",
        "outputId": "40763798-0b0b-491d-93e4-dcf98b1336b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting py-stringmatching\n",
            "  Downloading py_stringmatching-0.4.3.tar.gz (643 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.8/643.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from py-stringmatching) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from py-stringmatching) (1.16.0)\n",
            "Building wheels for collected packages: py-stringmatching\n",
            "  Building wheel for py-stringmatching (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-stringmatching: filename=py_stringmatching-0.4.3-cp39-cp39-linux_x86_64.whl size=2601563 sha256=4dd0a7df2ff2785c84641e6bbb5f62a27b4bc4100b6bd461dd459e75a3cff928\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/f9/e2/89e3ea9801245b19c9c6c365eb4c25afde526cea5e1e296ad9\n",
            "Successfully built py-stringmatching\n",
            "Installing collected packages: py-stringmatching\n",
            "Successfully installed py-stringmatching-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from re import finditer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from owlready2 import get_ontology\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "xfvNKt0XxLXv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifwlzEwgfbnG",
        "outputId": "fdf540fe-694b-4460-fce8-ddd01c5be04d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ngram\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.corpus import wordnet\n",
        "from py_stringmatching.similarity_measure.affine import Affine\n",
        "from py_stringmatching.similarity_measure.bag_distance import BagDistance\n",
        "from py_stringmatching.similarity_measure.cosine import Cosine\n",
        "from py_stringmatching.similarity_measure.dice import Dice\n",
        "from py_stringmatching.similarity_measure.editex import Editex\n",
        "from py_stringmatching.similarity_measure.generalized_jaccard import GeneralizedJaccard\n",
        "from py_stringmatching.similarity_measure.jaccard import Jaccard\n",
        "from py_stringmatching.similarity_measure.jaro import Jaro\n",
        "from py_stringmatching.similarity_measure.jaro_winkler import JaroWinkler\n",
        "from py_stringmatching.similarity_measure.levenshtein import Levenshtein\n",
        "from py_stringmatching.similarity_measure.monge_elkan import MongeElkan\n",
        "from py_stringmatching.similarity_measure.needleman_wunsch import NeedlemanWunsch\n",
        "from py_stringmatching.similarity_measure.overlap_coefficient import OverlapCoefficient\n",
        "from py_stringmatching.similarity_measure.partial_ratio import PartialRatio\n",
        "from py_stringmatching.similarity_measure.partial_token_sort import PartialTokenSort\n",
        "from py_stringmatching.similarity_measure.ratio import Ratio\n",
        "from py_stringmatching.similarity_measure.smith_waterman import SmithWaterman\n",
        "from py_stringmatching.similarity_measure.soft_tfidf import SoftTfIdf\n",
        "from py_stringmatching.similarity_measure.soundex import Soundex\n",
        "from py_stringmatching.similarity_measure.tfidf import TfIdf\n",
        "from py_stringmatching.similarity_measure.token_sort import TokenSort\n",
        "from py_stringmatching.similarity_measure.tversky_index import TverskyIndex\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "47_M-OeNZNKc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-BTuUUeYMdq",
        "outputId": "b7ebd42a-deaf-457d-8948-2a00be3c2df8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Datasets"
      ],
      "metadata": {
        "id": "kkV1rRLP2L1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ontology(path):\n",
        "    onto = get_ontology(path)\n",
        "    onto.load()\n",
        "\n",
        "    # read classes\n",
        "    classes = []\n",
        "    for cls in onto.classes():\n",
        "        classes.append(cls)\n",
        "    # print(classes)\n",
        "    # print(len(classes))\n",
        "    # print(len(set(classes)))\n",
        "    classes = list(set(classes))  # removing any number of repetitions of a class\n",
        "\n",
        "    # read properties\n",
        "    properties = []\n",
        "    for prop in onto.properties():\n",
        "        properties.append(prop)\n",
        "    properties = list(set(properties))\n",
        "\n",
        "    return classes, properties"
      ],
      "metadata": {
        "id": "ShFUEwVnxwXf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mappings(path):\n",
        "    mappings = []\n",
        "    with open(path) as map_file:\n",
        "        soup = BeautifulSoup(map_file, 'xml')\n",
        "\n",
        "    for cell in soup.find_all('Cell'):\n",
        "        entity1 = cell.find('entity1')['rdf:resource'].split('#')[1]\n",
        "        entity2 = cell.find('entity2')['rdf:resource'].split('#')[1]\n",
        "        mapping = (entity1, entity2)\n",
        "        mappings.append(mapping)\n",
        "\n",
        "    return mappings"
      ],
      "metadata": {
        "id": "5xhCMqYBzrEg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_path(cls):\n",
        "    path = cls.name\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            path = path + '/' + cls.is_a[0].name\n",
        "        except:\n",
        "            break\n",
        "        cls = cls.is_a[0]\n",
        "        if cls == 'owl.Thing':\n",
        "            break\n",
        "    \n",
        "    return '/'.join(path.split('/')[::-1])"
      ],
      "metadata": {
        "id": "p2KwvdjI4Jvk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(onto1, onto2, map_file):\n",
        "    data = []\n",
        "\n",
        "    mappings = get_mappings(map_file)\n",
        "    classes1, properties1 = read_ontology(onto1)\n",
        "    classes2, properties2 = read_ontology(onto2)\n",
        "\n",
        "    class_pairs = list(itertools.product(classes1, classes2))\n",
        "    for pair in class_pairs:\n",
        "        temp = pair\n",
        "        pair = (pair[0].name, pair[1].name)\n",
        "        if pair in mappings:\n",
        "            matched = 1\n",
        "        else:\n",
        "            matched = 0\n",
        "\n",
        "        data.append((onto1, onto2, pair[0], pair[1], temp[0], temp[1], get_path(temp[0]), get_path(temp[1]), matched, 'Class'))\n",
        "\n",
        "    property_pairs = list(itertools.product(properties1, properties2))\n",
        "    for pair in property_pairs:\n",
        "        temp = pair\n",
        "        pair = (pair[0].name, pair[1].name)\n",
        "        if pair in mappings:\n",
        "            matched = 1\n",
        "        else:\n",
        "            matched = 0\n",
        "\n",
        "        data.append((onto1, onto2, pair[0], pair[1], temp[0], temp[1], get_path(temp[0]), get_path(temp[1]), matched, 'Property'))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['Ontology1', 'Ontology2', 'Entity1', 'Entity2', 'Parent1', 'Parent2', 'Full Path1', 'Full Path2', 'Match', 'Type'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "Vwzm5ril9Ha-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Features"
      ],
      "metadata": {
        "id": "Qls3toVX2QPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/GoogleNews-vectors-negative300.bin.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itRumr9GYiGB",
        "outputId": "4a2d7af2-c9c2-421b-b864-debe8e49ad0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/GoogleNews-vectors-negative300.bin.zip\n",
            "  inflating: GoogleNews-vectors-negative300.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def camel_case_split(identifier):\n",
        "    matches = finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)',\n",
        "                       identifier)\n",
        "    return [m.group(0) for m in matches]"
      ],
      "metadata": {
        "id": "xlw86_oLZcS8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word2vec_sim(row_set1, row_set2):\n",
        "    sum_sim = 0\n",
        "    N = max(len(row_set1), len(row_set2))\n",
        "\n",
        "    for w1 in row_set1:\n",
        "        maxSim = 0\n",
        "        for w2 in row_set2:\n",
        "            try:\n",
        "                sim = model.wv.similarity(w1, w2)\n",
        "            except:\n",
        "                sim = 0\n",
        "\n",
        "            if sim > maxSim:\n",
        "                maxSim = sim\n",
        "        sum_sim = sum_sim + maxSim\n",
        "\n",
        "    sum_sim = sum_sim / N\n",
        "\n",
        "    return sum_sim"
      ],
      "metadata": {
        "id": "_wxP5w_yZgz7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words(text):\n",
        "    if '_' in text:\n",
        "        row_set = text.split('_')\n",
        "    else:\n",
        "        if '-' in text:\n",
        "            row_set = text.split('-')\n",
        "        else:\n",
        "            row_set = camel_case_split(text)\n",
        "\n",
        "    row_set = [x.lower() for x in row_set]\n",
        "    return row_set"
      ],
      "metadata": {
        "id": "wejItFLlZmgL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_features(dataset, string_type):\n",
        "    ngrams1 = []\n",
        "    ngrams2 = []\n",
        "    ngrams3 = []\n",
        "    ngrams4 = []\n",
        "    dices = []\n",
        "    jaccards = []\n",
        "    jaros = []\n",
        "    mes = []\n",
        "    sws = []\n",
        "    afs = []\n",
        "    bds = []\n",
        "    coses = []\n",
        "    prs = []\n",
        "    sfs = []\n",
        "    edxs = []\n",
        "    gjs = []\n",
        "    jws = []\n",
        "    lws = []\n",
        "    ptss = []\n",
        "    rats = []\n",
        "    sounds = []\n",
        "    tfidfs = []\n",
        "    tss = []\n",
        "    tvs = []\n",
        "    ovs = []\n",
        "    nws = []\n",
        "    wordnet_sims = []\n",
        "    w2vec_sims = []\n",
        "\n",
        "    if string_type == 'Entity':\n",
        "        index = 2\n",
        "    elif string_type == 'Parent':\n",
        "        index = 4\n",
        "    elif string_type == 'Path':\n",
        "        index = 6\n",
        "\n",
        "    for key, row in tqdm(dataset.iterrows()):\n",
        "\n",
        "        string1 = row[index]\n",
        "        string2 = row[index + 1]\n",
        "\n",
        "        ngrams1.append(ngram.NGram.compare(string1, string2, N=1))\n",
        "        ngrams2.append(ngram.NGram.compare(string1, string2, N=2))\n",
        "        ngrams3.append(ngram.NGram.compare(string1, string2, N=3))\n",
        "        ngrams4.append(ngram.NGram.compare(string1, string2, N=4))\n",
        "        lws.append(lev.get_sim_score(string1, string2))\n",
        "        jaros.append(jaro.get_sim_score(string1, string2))\n",
        "        nws.append(nw.get_raw_score(string1, string2))\n",
        "        sws.append(sw.get_raw_score(string1, string2))\n",
        "        afs.append(af.get_raw_score(string1, string2))\n",
        "        bds.append(bd.get_sim_score(string1, string2))\n",
        "        prs.append(pr.get_sim_score(string1, string2))\n",
        "        edxs.append(edx.get_sim_score(string1, string2))\n",
        "        ptss.append(pts.get_sim_score(string1, string2))\n",
        "        rats.append(rat.get_sim_score(string1, string2))\n",
        "        sounds.append(sound.get_sim_score(string1, string2))\n",
        "        tss.append(ts.get_sim_score(string1, string2))\n",
        "        jws.append(jw.get_sim_score(string1, string2))\n",
        "\n",
        "        row_set1 = get_words(string1)\n",
        "        row_set2 = get_words(string2)\n",
        "\n",
        "        mes.append(me.get_raw_score(row_set1, row_set2))\n",
        "        coses.append(cos.get_sim_score(row_set1, row_set2))\n",
        "        sfs.append(sf.get_raw_score(row_set1, row_set2))\n",
        "        gjs.append(gj.get_sim_score(row_set1, row_set2))\n",
        "        tfidfs.append(tfidf.get_sim_score(row_set1, row_set2))\n",
        "        tvs.append(tv_ind.get_sim_score(row_set1, row_set2))\n",
        "        ovs.append(over_coef.get_sim_score(row_set1, row_set2))\n",
        "        dices.append(dice.get_sim_score(row_set1, row_set2))\n",
        "        jaccards.append(jac.get_sim_score(row_set1, row_set2))\n",
        "\n",
        "        allsyns1 = set(ss for word in row_set1 for ss in wordnet.synsets(word))\n",
        "        allsyns2 = set(ss for word in row_set2 for ss in wordnet.synsets(word))\n",
        "\n",
        "        best = [wordnet.wup_similarity(s1, s2) for s1, s2 in itertools.product(allsyns1, allsyns2)]\n",
        "        if len(best) > 0:\n",
        "            wordnet_sims.append(best[0])\n",
        "        else:\n",
        "            wordnet_sims.append(0)\n",
        "\n",
        "        w2vec_sims.append(get_word2vec_sim(row_set1, row_set2))\n",
        "\n",
        "    dataset['Ngram1' + '_' + string_type] = ngrams1\n",
        "    dataset['Ngram2' + '_' + string_type] = ngrams2\n",
        "    dataset['Ngram3' + '_' + string_type] = ngrams3\n",
        "    dataset['Ngram4' + '_' + string_type] = ngrams4\n",
        "    dataset['Dice' + '_' + string_type] = dices\n",
        "    dataset['Jaccard' + '_' + string_type] = jaccards\n",
        "    dataset['Jaro' + '_' + string_type] = jaros\n",
        "    dataset['Monge-Elkan' + '_' + string_type] = mes\n",
        "    dataset['SmithWaterman' + '_' + string_type] = sws\n",
        "    dataset['AffineGap' + '_' + string_type] = afs\n",
        "    dataset['BagDistance' + '_' + string_type] = bds\n",
        "    dataset['Cosine_similarity' + '_' + string_type] = coses\n",
        "    dataset['PartialRatio' + '_' + string_type] = prs\n",
        "    dataset['Soft_TFIDF' + '_' + string_type] = sfs\n",
        "    dataset['Editex' + '_' + string_type] = edxs\n",
        "    dataset['GeneralizedJaccard' + '_' + string_type] = gjs\n",
        "    dataset['JaroWinkler' + '_' + string_type] = jws\n",
        "    dataset['Levenshtein' + '_' + string_type] = lws\n",
        "    dataset['PartialTokenSort' + '_' + string_type] = ptss\n",
        "    dataset['Ratio' + '_' + string_type] = rats\n",
        "    dataset['Soundex' + '_' + string_type] = sounds\n",
        "    dataset['TFIDF' + '_' + string_type] = tfidfs\n",
        "    dataset['TokenSort' + '_' + string_type] = tss\n",
        "    dataset['TverskyIndex' + '_' + string_type] = tvs\n",
        "    dataset['OverlapCoef' + '_' + string_type] = ovs\n",
        "    dataset['Needleman-Wunsch' + '_' + string_type] = nws\n",
        "    dataset['Wordnet_sim' + '_' + string_type] = wordnet_sims\n",
        "    dataset['Word2vec_sim' + '_' + string_type] = w2vec_sims\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "bDDKP64zZxsO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "af = Affine()\n",
        "me = MongeElkan()\n",
        "nw = NeedlemanWunsch()\n",
        "sw = SmithWaterman()\n",
        "bd = BagDistance()\n",
        "cos = Cosine()\n",
        "pr = PartialRatio()\n",
        "sf = SoftTfIdf()\n",
        "edx = Editex()\n",
        "gj = GeneralizedJaccard()\n",
        "jw = JaroWinkler()\n",
        "lev = Levenshtein()\n",
        "dice = Dice()\n",
        "jac = Jaccard()\n",
        "jaro = Jaro()\n",
        "pts = PartialTokenSort()\n",
        "rat = Ratio()\n",
        "sound = Soundex()\n",
        "tfidf = TfIdf()\n",
        "ts = TokenSort()\n",
        "tv_ind = TverskyIndex()\n",
        "over_coef = OverlapCoefficient()\n",
        "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "metadata": {
        "id": "Aph25Vha1pqx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset"
      ],
      "metadata": {
        "id": "jNEQ4xjX2AD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ontologies = ['101.rdf', '102.rdf', '103.rdf', '301.rdf', '302.rdf', '303.rdf', '304.rdf']\n",
        "train_aligns = ['101-102.rdf', '101-103.rdf', '101-301.rdf']\n",
        "test_aligns = ['101-302.rdf', '101-303.rdf', '101-304.rdf']\n",
        "\n",
        "train_datasets = []\n",
        "\n",
        "# Create dataset\n",
        "for align in train_aligns:\n",
        "    ont1, ont2 = align.split('.')[0].split('-')\n",
        "\n",
        "    ont1_path = '/content/' + ont1 + '.rdf'\n",
        "    ont2_path = '/content/' + ont2 + '.rdf'\n",
        "    alignment_path = '/content/' + align\n",
        "\n",
        "    train_datasets.append(get_dataset(ont1_path, ont2_path, alignment_path))\n",
        "\n",
        "train = pd.concat(train_datasets, ignore_index=True)\n",
        "\n",
        "test_datasets = []\n",
        "\n",
        "for align in test_aligns:\n",
        "    ont1, ont2 = align.split('.')[0].split('-')\n",
        "\n",
        "    ont1_path = '/content/' + ont1 + '.rdf'\n",
        "    ont2_path = '/content/' + ont2 + '.rdf'\n",
        "    alignment_path = '/content/' + align\n",
        "\n",
        "    test_datasets.append(get_dataset(ont1_path, ont2_path, alignment_path))\n",
        "\n",
        "test = pd.concat(test_datasets, ignore_index=True)\n",
        "\n",
        "train.to_csv('/content/dataset_train.csv', index=False)\n",
        "test.to_csv('/content/dataset_test.csv', index=False)"
      ],
      "metadata": {
        "id": "0lpumerS1KQI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Features"
      ],
      "metadata": {
        "id": "EYl1utwI2T7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate features for training dataset\n",
        "data = pd.read_csv('dataset_train.csv')\n",
        "\n",
        "data = calculate_features(data, 'Entity')\n",
        "data = calculate_features(data, 'Parent')\n",
        "data = calculate_features(data, 'Path')\n",
        "\n",
        "data.to_csv('dataset_train_features.csv', index=False)\n",
        "\n",
        "# Calculate features for testing dataset\n",
        "data = pd.read_csv('dataset_test.csv')\n",
        "\n",
        "data = calculate_features(data, 'Entity')\n",
        "data = calculate_features(data, 'Parent')\n",
        "data = calculate_features(data, 'Path')\n",
        "\n",
        "data.to_csv('dataset_test_features.csv', index=False)"
      ],
      "metadata": {
        "id": "aCohvXsb17eD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f4980d-6395-4e3a-9baf-77d2a40b9f0e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14148it [04:41, 50.34it/s]\n",
            "14148it [00:59, 236.62it/s]\n",
            "14148it [01:59, 118.42it/s]\n",
            "14940it [04:16, 58.33it/s]\n",
            "14940it [01:03, 236.59it/s]\n",
            "14940it [01:59, 124.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate"
      ],
      "metadata": {
        "id": "QvgwxSYR2FRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_lr_model(X_train, y_train, X_test, y_test):\n",
        "    model = LogisticRegression(penalty='l2', C=7.742637, class_weight=None)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    y_prob = model.predict_proba(X_test)\n",
        "\n",
        "    return y_prob"
      ],
      "metadata": {
        "id": "M9lJFGyYjKA0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def train_rf_model(X_train, y_train, X_test,y_test):\n",
        "    model = RandomForestClassifier(n_estimators=400, max_features='sqrt', max_depth=5, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    y_prob = model.predict_proba(X_test)\n",
        "\n",
        "    return y_prob"
      ],
      "metadata": {
        "id": "jvLrN3S8kFUe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def train_xgb_model(Xy_train, Xy_test):\n",
        "    param = {'silent': 0, 'objective': 'binary:logistic',\n",
        "                'min_child_weight': 10, 'gamma': 2.0, 'subsample': 0.8,\n",
        "                'colsample_bytree': 0.8, 'max_depth': 10, 'nthread': 6,\n",
        "                'eval_metric': 'error'}\n",
        "    evallist = [(Xy_test, 'eval'), (Xy_train, 'train')]\n",
        "    num_round = 20\n",
        "    \n",
        "    # Train model\n",
        "    bst = xgb.train(param, Xy_train, num_round, evallist,\n",
        "                    verbose_eval=False)\n",
        "\n",
        "    y_prob = bst.predict(Xy_test)\n",
        "\n",
        "    return y_prob"
      ],
      "metadata": {
        "id": "w4JrrjM9mWnn"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model = 'RandomForest'\n",
        "\n",
        "train_features = pd.read_csv('dataset_train_features.csv')\n",
        "test_features = pd.read_csv('dataset_test_features.csv')\n",
        "\n",
        "# Create feature \"Type\" for training dataset\n",
        "train_types = []\n",
        "\n",
        "for row in train_features['Type']:\n",
        "    if row == 'Class':\n",
        "        train_types.append(1)\n",
        "    else:\n",
        "        train_types.append(0)\n",
        "\n",
        "train_features['Type_encode'] = train_types\n",
        "\n",
        "# Create feature \"Type\" for testing dataset\n",
        "test_types = []\n",
        "\n",
        "for row in test_features['Type']:\n",
        "    if row == 'Class':\n",
        "        test_types.append(1)\n",
        "    else:\n",
        "        test_types.append(0)\n",
        "\n",
        "test_features['Type_encode'] = test_types\n",
        "\n",
        "X_train = train_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
        "y_train = train_features['Match']\n",
        "\n",
        "X_test = test_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
        "y_test = test_features['Match']\n",
        "\n",
        "df_train = train_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
        "df_train['Match'] = train_features['Match']\n",
        "\n",
        "df_test = test_features.loc[:, 'Ngram1_Entity':'Type_encode']\n",
        "df_test['Match'] = test_features['Match']\n",
        "\n",
        "# Fill nan values with zero\n",
        "X_train = X_train.fillna(value=0)\n",
        "X_test = X_test.fillna(value=0)\n",
        "\n",
        "train = pd.read_csv('dataset_train.csv')\n",
        "test = pd.read_csv('dataset_test.csv')\n",
        "\n",
        "if selected_model != 'XGBoost':\n",
        "    if selected_model == 'LogisticRegression':\n",
        "        y_prob = train_lr_model(X_train, y_train, X_test, y_test)\n",
        "    elif selected_model == 'RandomForest':\n",
        "        y_prob = train_rf_model(X_train, y_train, X_test, y_test)\n",
        "else:\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "    y_prob = train_xgb_model(dtrain, dtest)\n",
        "\n",
        "# Choose best threshold\n",
        "for align in test_aligns:\n",
        "    ont1, ont2 = align.split('.')[0].split('-')\n",
        "    best_ts = 0\n",
        "    best_score = 0\n",
        "\n",
        "    for ts in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        if selected_model != 'XGBoost':\n",
        "            for x in y_prob:\n",
        "                if x[1] >= ts:\n",
        "                    preds.append(1)\n",
        "                else:\n",
        "                    preds.append(0)\n",
        "        else:\n",
        "            for x in y_prob:\n",
        "                if x >= ts:\n",
        "                    preds.append(1)\n",
        "                else:\n",
        "                    preds.append(0)\n",
        "\n",
        "        test['Predict'] = preds\n",
        "\n",
        "        pred_mappings = test[(test['Ontology1'] == f\"/content/{ont1}.rdf\") & (test['Ontology2'] == f\"/content/{ont2}.rdf\") & (test['Predict'] == 1)]\n",
        "\n",
        "        true_mappings = test[(test['Ontology1'] == f\"/content/{ont1}.rdf\") & (test['Ontology2'] == f\"/content/{ont2}.rdf\") & (test['Match'] == 1)]\n",
        "\n",
        "        correct_mappings = test[(test['Ontology1'] == f\"/content/{ont1}.rdf\") & (test['Ontology2'] == f\"/content/{ont2}.rdf\") & (test['Match'] == 1) & (test['Predict'] == 1)]\n",
        "\n",
        "        true_count = len(true_mappings)\n",
        "        pred_count = len(pred_mappings)\n",
        "        corr_count = len(correct_mappings)\n",
        "\n",
        "        if pred_count != 0 and true_count != 0 and corr_count != 0:\n",
        "            precision = corr_count / pred_count\n",
        "            recall = corr_count / true_count\n",
        "            score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            score = 0\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_ts = ts\n",
        "            best_preds = preds\n",
        "\n",
        "    print(\n",
        "        f\"Best F1-Score for {align} is {best_score} with threshold {best_ts}\")"
      ],
      "metadata": {
        "id": "4OIriBce1fbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e25fe8-13f6-4d4a-d0b0-fc2824ac7b65"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1-Score for 101-302.rdf is 0.7012987012987012 with threshold 0.3\n",
            "Best F1-Score for 101-303.rdf is 0.7959183673469388 with threshold 0.3\n",
            "Best F1-Score for 101-304.rdf is 0.9240506329113924 with threshold 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvewSW9BlQzB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}